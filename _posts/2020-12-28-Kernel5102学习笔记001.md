---
layout:     post
title:      Kernel 5.10.2
subtitle:   Kernel 学习笔记
date:       2020-12-28
author:     Jeff
header-img: img/bg_wolf.jpg
catalog: true
tags:
    - Kernel
    - Code
    - 
---

>Kernel 学习笔记

# 内核常用到的宏：
### \_\_read\_mostly:


 		##宏定义在 arch/arm/include/asm/cache.h
 	#define __read_mostly __attribute__((__section__(".data..read_mostly"))) 
 		##实例：
 	bool early_boot_irqs_disabled __read_mostly;
 		##用来标记 early_boot_irqs_disabled 这个变量经常被读取，如果平台支持缓存，会把这个变量放到cache中
 
 
###  \_\_initdata:
		##宏定义在include/linux/init.h
	#define __initdata    __section(.init.data)
	#define __initconst    __constsection(.init.rodata)
		##实例：
	char __initdata boot_command_line[COMMAND_LINE_SIZE];
		##同上面__read_mostly一样，是用来把这个变量绑定在某个区里面

![](https://jeffnoteimgs.oss-cn-shanghai.aliyuncs.com/imgs20201228163641.png)

### \_\_init、\_\_exit：
	#define __init        __section(.init.text) __cold notrace
		##实例：
	static int __init forward_init_module(void)
		##用于标记函数，放在.init.text section，标记为初始化的函数,表明该函数供在初始化期间使用。在模块装载之后，模块装载就会将初始化函数扔掉。这样可以将该函数占用的内存释放出来。
		
		#define __exit          __section(".exit.text") __exitused __cold notrace
		##实例：
		static void __exit forward_uninit_module(void)
		
### \_\_cold:
	#define __cold   __attribute__((__cold__))
		##__cold告诉编译器这个函数很可能不被执行到
		
### notrace:
	#define notrace __attribute__((no_instrument_function))
		##notrace如同GCC的-finstrument-functions（） 参数的作用是在程序中加入hook，让它在每次进入和退出函数的时候分别调用这个函数

### noinline:
	#define  noinline   __attribute__((noinline))  
		##阻止该函数被内联

### \_\_setup 和 early_param:
	unsigned int reset_devices;
	EXPORT_SYMBOL(reset_devices);
	static int __init set_reset_devices(char *str)
	{
		reset_devices = 1;
		return 1;
	}
	__setup("reset_devices", set_reset_devices);
	
		##__setup，这个函数就理解为：启动时候如果有接收reset_devices参数，那么就调用set_reset_devices方法
		##与__setup相对应的还有一个叫做early_param。这两个宏函数的功能一样，区别就在于early_param定义的参数比__setup更早

# 源码：
---
>							进入源码部分

---
>走完引导阶段，进入内核入口函数start_kernel()：(在init/main.c中)

```c
asmlinkage __visible void __init __no_sanitize_address start_kernel(void){
```

* 第一个被调用的函数，用来设置栈溢出标志
	1. [set\_task\_stack\_end\_magic(&init_task);](#set_task_stack_end_magic)
* 设置smp即多处理模型，x86_64是空函数
	2. [smp\_setup_processor\_id();](#smp_setup_processor_id)
* 初始化调试相关变量
	3. [debug\_objects\_early\_init();](#debug_objects_early_init)
* cgroup 初始化
	3. [cgroup\_init\_early();](#cgroup_init_early)

      
     
```c
}
```
---

>一个函数一个函数来，我们先看<span id="set_task_stack_end_magic">set\_task\_stack\_end\_magic()</span>:(在 kernel/fork.c中)
> 主要用来设置栈溢出标志，方便溢出检查。
> >  #define STACK_END_MAGIC    0x57AC6E9D

```c
void set_task_stack_end_magic(struct task_struct *tsk){	unsigned long *stackend;	//获取栈边界地址	stackend = end_of_stack(tsk);	*stackend = STACK_END_MAGIC;	/* for overflow detection */}
```
	其中参数init_task定义在 init/init_task.c中静态初始，是系统中第一个进程：

```c
	struct task_struct init_task = {#ifdef CONFIG_THREAD_INFO_IN_TASK	.thread_info	= INIT_THREAD_INFO(init_task),	.stack_refcount	= REFCOUNT_INIT(1),#endif	.............................................................	.stack		= init_stack,	..............................................................};

union thread_union {#ifndef CONFIG_ARCH_TASK_STRUCT_ON_STACK	struct task_struct task;#endif#ifndef CONFIG_THREAD_INFO_IN_TASK	struct thread_info thread_info;#endif	unsigned long stack[THREAD_SIZE/sizeof(long)];};
```
>每个task的内核栈大小THREAD_SIZE，在32位系统是8KB，64位系统里是16KB

	x86：
		#define THREAD_SIZE_ORDER	1
		#define THREAD_SIZE		(PAGE_SIZE << THREAD_SIZE_ORDER)
		因此是8K
	x86_64：
		#define THREAD_SIZE_ORDER	(2 + KASAN_STACK_ORDER)
		#define THREAD_SIZE  (PAGE_SIZE << THREAD_SIZE_ORDER)
		PAGE_SIZE默认4K，KASAN_STACK_ORDER没有定义时为0，因此是16K;  KASAN:动态内存错误检测工具，常用来发现用后释放和越界的bug
	
	ARM：
		8k
	ARM64：
        	16K
      
>task\_struct、thread\_info都用来保存进程相关信息，即进程PCB信息。然而不同的体系结构里，进程需要存储的信息不尽相同，linux使用task\_struct存储通用的信息，将体系结构相关的部分存储在thread\_info中。这也是为什么struct task\_struct在include/linux/sched.h中定义，而thread\_info 在arch/ 下体系结构相关头文件里

```c
	/* x86 */
	struct thread_info {
		unsigned long		flags;		/* low level flags */
		u32			status;		/* thread synchronous flags */
	};

	/* ARM */
	struct thread_info {
		unsigned long		flags;		/* low level flags */
		int			preempt_count;	/* 0 => preemptable, <0 => bug */
		mm_segment_t		addr_limit;	/* address limit */
		struct task_struct	*task;		/* main task structure */
		… …
	};
```




><span id="smp_setup_processor_id"> smp\_setup\_processor\_id()</span>:(在 arch/cpu架构/kernel/setup.c中)


```c
	//X86_64
	void __init __weak smp_setup_processor_id(void)	{	}
	
	//ARM64
	void __init smp_setup_processor_id(void)	{
		//获取CPU ID		u64 mpidr = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;		set_cpu_logical_map(0, mpidr);		/*		 * clear __my_cpu_offset on boot CPU to avoid hang caused by		 * using percpu variable early, for example, lockdep will		 * access percpu variable inside lock_release	 	*/		set_my_cpu_offset(0);		pr_info("Booting Linux on physical CPU 0x%010lx [0x%08x]\n",(unsigned long)mpidr, read_cpuid_id());	}
	
	//ARM32
	void __init smp_setup_processor_id(void)	{		int i;
		//判断是否是smp系统,如果是则从arm协处理器读取当前cpuid,否则为0		u32 mpidr = is_smp() ? read_cpuid_mpidr() & MPIDR_HWID_BITMASK : 0;
		//根据level确定cpu号，即cpu=(mpidr>>0)&0xff		u32 cpu = MPIDR_AFFINITY_LEVEL(mpidr, 0);		cpu_logical_map(0) = cpu;		for (i = 1; i < nr_cpu_ids; ++i)			cpu_logical_map(i) = i == cpu ? 0 : i;		/*		 * clear __my_cpu_offset on boot CPU to avoid hang caused by		 * using percpu variable early, for example, lockdep will		 * access percpu variable inside lock_release		 */		set_my_cpu_offset(0);		pr_info("Booting Linux on physical CPU 0x%x\n", mpidr);	}
	
```

><span id="debug_objects_early_init"> debug\_objects\_early\_init()</span>:(在 lib/debugobjects.c中) ,主要用来初始化obj\_hash，obj\_static\_pool两个全局变量

```c
/* * Called during early boot to initialize the hash buckets and link * the static object pool objects into the poll list. After this call * the object tracker is fully operational. */void __init debug_objects_early_init(void){	int i;	for (i = 0; i < ODEBUG_HASH_SIZE; i++)		raw_spin_lock_init(&obj_hash[i].lock);	for (i = 0; i < ODEBUG_POOL_SIZE; i++)		hlist_add_head(&obj_static_pool[i].node, &obj_pool);}
```

><span id="cgroup_init_early"> cgroup\_init\_early()</span>:(在 kernel/cgroup.c中) ,

### 什么是CGROUP:
	cgroups是Linux下控制一个（或一组）进程的资源限制机制，全称是control groups;
	可以对cpu、内存等资源做精细化控制，比如目前很多的Docker在Linux下就是基于cgroups提供的资源限制机制来实现资源控制的.
	在cgroup出现之前，只能对一个进程做资源限制，比如通过sched_setaffinity设置进程cpu亲和性，使用ulimit限制进程打开文件上限、栈大小等。
	
	从实现角度来看，cgroups实现了一个通用的进程分组框架，不同资源的具体管理工作由各cgroup子系统来实现，
	当需要多个限制策略比如同时针对cpu和内存进行限制，则同时关联多个cgroup子系统即可.
	
	cgroups子系统
		cgroups为每种资源定义了一个子系统，典型的子系统如下：

		cpu 子系统，主要限制进程的 cpu 使用率。
		cpuacct 子系统，可以统计 cgroups 中的进程的 cpu 使用报告。
		cpuset 子系统，可以为 cgroups 中的进程分配单独的 cpu 节点或者内存节点。
		memory 子系统，可以限制进程的 memory 使用量。
		blkio 子系统，可以限制进程的块设备 io。
		devices 子系统，可以控制进程能够访问某些设备。
		net_cls 子系统，可以标记 cgroups 中进程的网络数据包，然后可以使用 tc 模块（traffic control）对数据包进行控制。
		freezer 子系统，可以挂起或者恢复 cgroups 中的进程。
		ns 子系统，可以使不同 cgroups 下面的进程使用不同的 namespace。
		
		
		每个子系统都是定义了一套限制策略，它们需要与内核的其他模块配合来完成资源限制功能，比如对 cpu 资源的限制是通过进程调度模块根据 cpu 子系统的配置来完成的；
		对内存资源的限制则是内存模块根据 memory 子系统的配置来完成的，而对网络数据包的控制则需要 Traffic Control 子系统来配合完成。
		
### cgroups原理:

> Linux 下管理进程的数据结构是 task_struct，其中与cgrups相关属性如下:

```c
	struct task_struct {
	.......
	#ifdef CONFIG_CGROUPS	/* Control Group info protected by css_set_lock: */	struct css_set __rcu		*cgroups;	/* cg_list protected by css_set_lock and tsk->alloc_lock: */	struct list_head		cg_list;	#endif
	......
	}
```

